{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "i2v5_fn3WhUa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xbgQokmAYW_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I7abezitYYlz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "from keras.utils import np_utils\n",
        "#把正確答案轉成矩陣型式\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H60xNwIGYlZD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential #有Sequential或functional api兩種神經網路\n",
        "from keras.layers import Dense, Activation #Dense是Fully connected的。Activation是設定激活函數用的。\n",
        "from keras.optimizers import SGD #把資料隨機打散用的"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "10lj6fdQYxhz",
        "colab_type": "code",
        "outputId": "50f35810-ff19-484e-de7d-0aec93e6e7a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=784)) #第一層，有20個神經元，輸入域有784個\n",
        "model.add(Activation('tanh'))#將上課的激活函數改成tanh\n",
        "model.add(Dense(10)) #第二層，有10個神經元，輸入域有784個\n",
        "model.add(Activation('tanh'))#將上課的激活函數改成tanh\n",
        "model.add(Dense(10)) #輸出層，有10維\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='mse', optimizer=SGD(lr=0.01), metrics=['accuracy']) #設定loss function，設定最佳化，設定顯示正確率\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 20)                15700     \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                210       \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,020\n",
            "Trainable params: 16,020\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XGmL_tOUYz78",
        "colab_type": "code",
        "outputId": "8e13612e-1d40-4f27-8711-623236d52148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3434
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size=100, epochs=100) #batch_size代表看完100筆資料，就調一次參數"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0184 - acc: 0.8908\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0184 - acc: 0.8903\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0182 - acc: 0.8916\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0180 - acc: 0.8925\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0181 - acc: 0.8920\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0179 - acc: 0.8928\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0178 - acc: 0.8932\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0178 - acc: 0.8928\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0178 - acc: 0.8939\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0176 - acc: 0.8941\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0176 - acc: 0.8942\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0174 - acc: 0.8954\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0174 - acc: 0.8956\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0173 - acc: 0.8962\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0171 - acc: 0.8970\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0171 - acc: 0.8971\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0172 - acc: 0.8966\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0169 - acc: 0.8977\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0168 - acc: 0.8978\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0168 - acc: 0.8981\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0166 - acc: 0.8995\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0166 - acc: 0.8995\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0165 - acc: 0.8999\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0164 - acc: 0.9010\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0164 - acc: 0.9009\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0165 - acc: 0.8990\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0166 - acc: 0.8987\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0163 - acc: 0.9014\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0161 - acc: 0.9023\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0162 - acc: 0.9019\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0161 - acc: 0.9029\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0160 - acc: 0.9025\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0159 - acc: 0.9033\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0160 - acc: 0.9021\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0158 - acc: 0.9042\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0158 - acc: 0.9039\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0158 - acc: 0.9030\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0156 - acc: 0.9056\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0156 - acc: 0.9050\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0156 - acc: 0.9046\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0156 - acc: 0.9048\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0155 - acc: 0.9059\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0154 - acc: 0.9062\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0155 - acc: 0.9055\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0153 - acc: 0.9067\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0154 - acc: 0.9063\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0151 - acc: 0.9080\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0151 - acc: 0.9085\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0151 - acc: 0.9081\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0151 - acc: 0.9076\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0151 - acc: 0.9078\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0150 - acc: 0.9083\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0149 - acc: 0.9090\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0149 - acc: 0.9090\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0149 - acc: 0.9088\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0149 - acc: 0.9090\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0147 - acc: 0.9104\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0147 - acc: 0.9109\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0148 - acc: 0.9088\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0149 - acc: 0.9085\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0147 - acc: 0.9098\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0148 - acc: 0.9094\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0147 - acc: 0.9099\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0146 - acc: 0.9098\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0146 - acc: 0.9105\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0144 - acc: 0.9111\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0145 - acc: 0.9104\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0145 - acc: 0.9109\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0145 - acc: 0.9109\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0145 - acc: 0.9103\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0144 - acc: 0.9110\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0143 - acc: 0.9112\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0142 - acc: 0.9125\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0142 - acc: 0.9124\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0142 - acc: 0.9123\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0141 - acc: 0.9135\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0142 - acc: 0.9131\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0140 - acc: 0.9141\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0142 - acc: 0.9120\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0140 - acc: 0.9132\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0139 - acc: 0.9140\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0139 - acc: 0.9142\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0139 - acc: 0.9145\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0139 - acc: 0.9141\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0140 - acc: 0.9139\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0139 - acc: 0.9142\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0139 - acc: 0.9135\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0138 - acc: 0.9150\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0138 - acc: 0.9144\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0139 - acc: 0.9143\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0138 - acc: 0.9143\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0138 - acc: 0.9150\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0137 - acc: 0.9154\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0137 - acc: 0.9155\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0135 - acc: 0.9172\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0136 - acc: 0.9158\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0135 - acc: 0.9164\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0134 - acc: 0.9175\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0134 - acc: 0.9178\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0134 - acc: 0.9168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7c60f0edd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "sakrllX0Y81k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "19025159-3cfc-472a-b231-f0593fe50663"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test)\n",
        "print('loss:', score[0])\n",
        "print('正確率', score[1])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 29us/step\n",
            "loss: 0.015023951000533999\n",
            "正確率 0.9028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kiqV5J3bla-5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}